{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mountain Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this Jupyter Notebook as part of the Mountain Sort process for spike sorting electrophysiological data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cells, we import the necessary modules and set up the dependencies to run the needed code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_path(dir0): # A convenience function\n",
    "    if dir0 not in sys.path:\n",
    "        sys.path.append(dir0)\n",
    "\n",
    "# standard imports\n",
    "import os, sys, json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# mountainlab imports\n",
    "from mountainlab_pytools import mlproc as mlp\n",
    "from mountainlab_pytools import mdaio\n",
    "\n",
    "# imports from this repo\n",
    "append_to_path('/home/stimulus/movshonMS4/python')\n",
    "import mountainsort4_1_0 as ms4 # MountainSort spike sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, you'll see the \"processors\" that are run as part of the ms4.sort_dataset pipeline. In short, this will go from input array to sorted clusters that you can view with mountainview (i.e. invoke qt-mountainview; see readme for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e3a1ce875e4466811fc2ee994450d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JSProxyWidget(status='Not yet rendered')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pipeline=mlp.initPipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we pick an example folder whose programs we can sort; you should replace this with the director(y/ies) you want to analyze. Our current pipeline expects that you create a separate directory for each program you want to sort.\n",
    "\n",
    "###  This directory will need three files\n",
    "#### 1. the *.ap.bin file from spikeGLX; should be renamed *.dat\n",
    "#### 2. the params.json file which should be found in this directory\n",
    "#### 3. an imro file (as a csv; most neuropixel recordings are with imro_1_384; in either case, find the needed imro file (we should have it in this directory), and copy over to the desired directory\n",
    "* Note: The default imro to work with is npx_1_384.csv; if you are using anything else, pass in geom_file = 'npx_A_B.csv' in the call to ms4.sort_dataset below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go through and list the directores:\n",
    "\n",
    "Note: If you know the specific directory you want to analyze, simply ignore this step and write the directory as dsdir in the cell labeled \"inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_main = os.walk('/experiments/ms4binaries/m678/levy/')\n",
    "[root,dirs,files] = next(files_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m678p6l12#12',\n",
       " 'm678p5l7#9',\n",
       " 'm678p5l6#7',\n",
       " 'm678p6l18#5',\n",
       " 'm678p6l17#6',\n",
       " 'm678p6l16#9',\n",
       " 'm678p7r3#8',\n",
       " 'm678p6l15#11',\n",
       " 'm678p6l11#9',\n",
       " 'm678p5l6#15']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, set the following inputs for the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either pick from the list of dirs\n",
    "# dir_ind = 3;\n",
    "# dsdir = root + dirs[dir_ind]\n",
    "# or set it directly\n",
    "dsdir = '/experiments/ms4binaries/m678/levy/m678p6l12#12';\n",
    "\n",
    "# output directory\n",
    "output_dir= dsdir # just set to input directory, unless you have a specific need otherwise\n",
    "\n",
    "# what is the name of the input file; remember, this is simply the *.ap.bin file from the GLX recording renamed\n",
    "input_file = 'sfMixHalfInt.dat'\n",
    "# which channel range will you analyze?\n",
    "# Note that the default naming convention will save all output files from the sorting pipeline \n",
    "# with the suffix \"_a_b\", where a/b are the first/second entries of chan_range\n",
    "chan_range = [21, 50];\n",
    "\n",
    "## The below likely won't need adjustment; values are stock/from Maniu\n",
    "adj_radius = 75\n",
    "detect_thres = 3\n",
    "detect_int = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c5c09f579e43ccb2b6a5ae682e2b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#in case you just want to do one file - which index is that in \"dirs\"?\n",
    "with Pipeline:\n",
    "    ms4.sort_dataset(dataset_dir=dsdir,output_dir=output_dir,input_file=input_file,adjacency_radius=adj_radius,detect_threshold=detect_thres,detect_interval=detect_int,chan_range=chan_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, your data has been sorted. You should really pore over the proposed sortings by eye. This should be done by invoking qt-mountainview (see movREADME.md). After that, you'll need to align this data with the Expo ticks/frametimes. Manu has written code on this, and collectively we are working on a streamlined code pipeline for integrating those spike times with the expo data structures (e.g. ReadExpoXML)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
